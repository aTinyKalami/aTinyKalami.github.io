<!DOCTYPE html>
<html lang="en">

<head>
	<meta http-equiv="content-type" content="text/html; charset=utf-8">
	<meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
	
	<!-- title -->
	
	<title>
	
		临时课题记录 | 
	 
	十二亚晖的个人空间
	</title>
	
	<!-- keywords,description -->
	
		<meta name="keywords" content="给时光以生命" />
	
	
		<meta name="description" content="临时课题记录，暂存待后续整理合入对应模块" />
	

	<!-- favicon -->
	
	<link rel="shortcut icon" href="/favicon.ico">
	


	<!-- search -->
	<script>
		var searchEngine = "https://www.google.com/search?q=";
		if(typeof searchEngine == "undefined" || searchEngine == null || searchEngine == ""){
			searchEngine = "https://www.google.com/search?q=";
		}
		var homeHost = "atinykalami.github.io";
		if(typeof homeHost == "undefined" || homeHost == null || homeHost == ""){
			homeHost = window.location.host;
		}
	</script>


	
<link rel="stylesheet" href="/css/main.css">

	
<link rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/4.7.0/css/font-awesome.min.css">

	
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.17.1/build/styles/darcula.min.css">

	
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css">


	
<script src="https://cdn.jsdelivr.net/npm/jquery@3.7.0/dist/jquery.min.js"></script>

	
<script src="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>

	
<script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.17.1/build/highlight.min.js"></script>

	
<script src="https://cdn.jsdelivr.net/npm/jquery-pjax@2.0.1/jquery.pjax.min.js"></script>

	
<script src="/js/main.js"></script>


	
		
<script src="https://cdn.jsdelivr.net/npm/leancloud-storage/dist/av-min.js"></script>

		
<script src="https://cdn.jsdelivr.net/npm/valine@v1.5.1/dist/Valine.min.js"></script>

	
	

<meta name="generator" content="Hexo 8.0.0"></head>

<body>
	<header id="header">
    <a id="title" href="/" class="logo">十二亚晖的个人空间</a>

	<ul id="menu">
    

    
      <li class="menu-item">
        <a href="/tags" class="menu-item-link">标签</a>
      </li>
    

    
      <li class="menu-item">
        <a href="/categories" class="menu-item-link">分类</a>
      </li>
    

    
      
      
        <li class="menu-item">
          <a href='https://github.com/aTinyKalami' class="menu-item-link" target="_blank">
            我的项目
          </a>
        </li>
      
        <li class="menu-item">
          <a href='https://github.com/aTinyKalami/blog-code-folder' class="menu-item-link" target="_blank">
            博客源码
          </a>
        </li>
      
    
  
    
      <li class="menu-item">
        <a href='https://github.com/aTinyKalami' class="menu-item-link" target="_blank">
          <i class="fa fa-github fa-2x"></i>
        </a>
      </li>
    
	</ul>
</header>

	
<div id="sidebar">
	<button id="sidebar-toggle" class="toggle" ><i class="fa fa-arrow-right " aria-hidden="true"></i></button>
	
	<div id="site-toc">
		<input id="search-input" class="search-input" type="search" placeholder="按回车全站搜索">
		<div id="tree">
			

			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										01 通用文档
									</a>
									
							<ul>
								<li class="file">
									<a href="/2025/10/05/01%20%E9%80%9A%E7%94%A8%E6%96%87%E6%A1%A3/2025-10-01-Markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%85%A5%E6%8C%87%E5%AF%BC/">
                     
										    01 Markdown格式文档输入规则
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2025/10/25/01%20%E9%80%9A%E7%94%A8%E6%96%87%E6%A1%A3/2025-10-02-HEXO%E6%A1%86%E6%9E%B6%E5%8D%9A%E5%AE%A2%E9%83%A8%E7%BD%B2%E6%94%BB%E7%95%A5/">
                     
										    02 Github上部署Hexo框架的博客的亲测爬坑攻略
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2025/10/25/01%20%E9%80%9A%E7%94%A8%E6%96%87%E6%A1%A3/2025-10-03-HEXO%E6%A1%86%E6%9E%B6%E5%8D%9A%E5%AE%A2%E6%89%8B%E5%8A%A8%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4/">
                     
										    03 Hexo框架的Github文章手工部署常用命令
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2025/10/05/01%20%E9%80%9A%E7%94%A8%E6%96%87%E6%A1%A3/2025-10-04-ipynb%E6%A0%BC%E5%BC%8F%E6%96%87%E6%A1%A3%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/">
                     
										    04 ipynb格式使用指导
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										03 AI学习
									</a>
									
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										00 AI知识地图
									</a>
									
							<ul>
								<li class="file">
									<a href="/2025/05/05/03%20AI%E5%AD%A6%E4%B9%A0/00%20AI%E7%9F%A5%E8%AF%86%E5%9C%B0%E5%9B%BE/2025-10-05-%E3%80%90AI%E5%AD%A6%E4%B9%A0%E3%80%91AI%E7%9F%A5%E8%AF%86%E5%9C%B0%E5%9B%BE/">
                     
										    AI知识地图
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										02 AI硬件体系
									</a>
									
							<ul>
								<li class="file">
									<a href="/2025/10/05/03%20AI%E5%AD%A6%E4%B9%A0/02%20AI%E7%A1%AC%E4%BB%B6%E4%BD%93%E7%B3%BB/2025-10-05-%E3%80%90AI%E5%AD%A6%E4%B9%A0%E3%80%91AI%E8%8A%AF%E7%89%87/">
                     
										    AI芯片
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2025/10/05/03%20AI%E5%AD%A6%E4%B9%A0/02%20AI%E7%A1%AC%E4%BB%B6%E4%BD%93%E7%B3%BB/2025-10-06-%E3%80%90AI%E5%AD%A6%E4%B9%A0%E3%80%91AI%E5%AD%98%E5%82%A8/">
                     
										    02 AI存储
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										04 AI模型与应用
									</a>
									
							<ul>
								<li class="file">
									<a href="/2025/10/05/03%20AI%E5%AD%A6%E4%B9%A0/04%20AI%E6%A8%A1%E5%9E%8B%E4%B8%8E%E5%BA%94%E7%94%A8/2025-01-01-%E3%80%90%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84%E3%80%91%E6%90%9E%E6%87%82%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84/">
                     
										    模型基础 - 搞懂大模型文件结构
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2025/10/05/03%20AI%E5%AD%A6%E4%B9%A0/04%20AI%E6%A8%A1%E5%9E%8B%E4%B8%8E%E5%BA%94%E7%94%A8/2025-01-02-%E3%80%90%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84%E3%80%91Transfomer%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84/">
                     
										    Transformer模型架构基础
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2025/10/05/03%20AI%E5%AD%A6%E4%B9%A0/04%20AI%E6%A8%A1%E5%9E%8B%E4%B8%8E%E5%BA%94%E7%94%A8/2025-01-03-%E3%80%90%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84%E3%80%91%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B/">
                     
										    多模态模型
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2025/10/05/03%20AI%E5%AD%A6%E4%B9%A0/04%20AI%E6%A8%A1%E5%9E%8B%E4%B8%8E%E5%BA%94%E7%94%A8/2025-02-01-%E3%80%90%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E3%80%91Tokenizer%E5%88%86%E8%AF%8D/">
                     
										    基础知识 - Tokeniazer分词
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2025/10/05/03%20AI%E5%AD%A6%E4%B9%A0/04%20AI%E6%A8%A1%E5%9E%8B%E4%B8%8E%E5%BA%94%E7%94%A8/2025-02-02-%E3%80%90%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E3%80%91Embedding%E8%AF%8D%E5%B5%8C%E5%85%A5/">
                     
										    基础知识 - Embedding (词嵌入/向量化)
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2025/10/05/03%20AI%E5%AD%A6%E4%B9%A0/04%20AI%E6%A8%A1%E5%9E%8B%E4%B8%8E%E5%BA%94%E7%94%A8/2025-03-01-%E3%80%90%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E3%80%91%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AE%AD%E6%8E%A8%E6%B5%81%E7%A8%8B%E4%B8%8E%E6%A1%86%E6%9E%B6/">
                     
										    训推框架 - 大模型训练和推理流程与框架
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2025/10/05/03%20AI%E5%AD%A6%E4%B9%A0/04%20AI%E6%A8%A1%E5%9E%8B%E4%B8%8E%E5%BA%94%E7%94%A8/2025-03-02-%E3%80%90%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E3%80%91%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E8%B6%85%E5%8F%82%E8%AE%BE%E7%BD%AE%E4%B8%8E%E6%96%B9%E6%B3%95/">
                     
										    模型训练 - 大模型训练超参设置与方法
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2025/10/02/03%20AI%E5%AD%A6%E4%B9%A0/04%20AI%E6%A8%A1%E5%9E%8B%E4%B8%8E%E5%BA%94%E7%94%A8/2025-04-01-%E3%80%90%E6%A8%A1%E5%9E%8B%E5%90%8E%E8%AE%AD%E7%BB%83%E3%80%91%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%90%8E%E8%AE%AD%E7%BB%83%E4%B8%8E%E5%BE%AE%E8%B0%83/">
                     
										    后训练 - 大模型后训练与微调
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2025/10/05/03%20AI%E5%AD%A6%E4%B9%A0/04%20AI%E6%A8%A1%E5%9E%8B%E4%B8%8E%E5%BA%94%E7%94%A8/2025-04-02-%E3%80%90%E6%A8%A1%E5%9E%8B%E5%90%8E%E8%AE%AD%E7%BB%83%E3%80%91%E5%A6%82%E4%BD%95%E8%AE%A9%E5%9F%BA%E7%A1%80%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%A1%8C%E4%B8%9A%E5%8C%96/">
                     
										    模型训练 - 基础大模型如何行业化训练
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2025/10/05/03%20AI%E5%AD%A6%E4%B9%A0/04%20AI%E6%A8%A1%E5%9E%8B%E4%B8%8E%E5%BA%94%E7%94%A8/2025-10-02-%E3%80%90AI%E6%A8%A1%E5%9E%8B%E3%80%91%E5%A4%A7%E6%A8%A1%E5%9E%8BAPI%E6%8E%A5%E5%8F%A3%E8%B0%83%E7%94%A8%E5%8F%82%E6%95%B0/">
                     
										    基础知识 - 大模型API接口调用参数说明
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2025/11/05/03%20AI%E5%AD%A6%E4%B9%A0/04%20AI%E6%A8%A1%E5%9E%8B%E4%B8%8E%E5%BA%94%E7%94%A8/2025-10-03-%E3%80%90AI%E6%A1%86%E6%9E%B6%E3%80%91RAY%E5%92%8CK8S%E5%AE%B9%E5%99%A8%E6%A1%86%E6%9E%B6%E7%9A%84%E5%85%B3%E7%B3%BB%E5%92%8C%E5%8C%BA%E5%88%AB/">
                     
										    AI框架 - 使用K8S容器框架和RAY的关系和区别
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2025/10/05/03%20AI%E5%AD%A6%E4%B9%A0/04%20AI%E6%A8%A1%E5%9E%8B%E4%B8%8E%E5%BA%94%E7%94%A8/2025-10-04-%E3%80%90AI%E5%BA%94%E7%94%A8%E3%80%91GraphRAG%E6%96%B9%E6%A1%88/">
                     
										    AI应用 - Graph RAG
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2025/10/05/03%20AI%E5%AD%A6%E4%B9%A0/04%20AI%E6%A8%A1%E5%9E%8B%E4%B8%8E%E5%BA%94%E7%94%A8/2025-10-04-%E3%80%90AI%E5%BA%94%E7%94%A8%E3%80%91RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/">
                     
										    AI应用 - RAG方案
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										09 动手实操
									</a>
									
							<ul>
								<li class="file">
									<a href="/2025/10/05/03%20AI%E5%AD%A6%E4%B9%A0/09%20%E5%8A%A8%E6%89%8B%E5%AE%9E%E6%93%8D/2025-01-01-%E3%80%90%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E3%80%91Huggingface%E7%9A%84%E6%A8%A1%E5%9E%8B%E5%92%8C%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/">
                     
										    Huggingface平台的模型和数据集使用
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2025/10/05/03%20AI%E5%AD%A6%E4%B9%A0/09%20%E5%8A%A8%E6%89%8B%E5%AE%9E%E6%93%8D/2025-01-01-%E3%80%90%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E3%80%91%E5%AE%89%E8%A3%85Evalscope%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E6%A1%86%E6%9E%B6/">
                     
										    安装Evalscope模型评估框架
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2025/10/05/03%20AI%E5%AD%A6%E4%B9%A0/09%20%E5%8A%A8%E6%89%8B%E5%AE%9E%E6%93%8D/2025-01-02-%E3%80%90%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E3%80%91%E7%B3%BB%E7%BB%9F%E7%8E%AF%E5%A2%83%E4%B8%8E%E5%B7%A5%E5%85%B7%E8%BD%AF%E4%BB%B6%E9%85%8D%E7%BD%AE/">
                     
										    实操系统环境与工具软件配置
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2025/10/05/03%20AI%E5%AD%A6%E4%B9%A0/09%20%E5%8A%A8%E6%89%8B%E5%AE%9E%E6%93%8D/2025-10-01-%E3%80%90%E5%8A%A8%E6%89%8B%E5%AE%9E%E6%93%8D%E3%80%91%E5%9C%A8%E7%BA%BF%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%9B%B6%E4%BB%A3%E7%A0%81%E5%BE%AE%E8%B0%83/">
                     
										    动手实操 - 在线大模型零代码微调
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2025/10/29/03%20AI%E5%AD%A6%E4%B9%A0/09%20%E5%8A%A8%E6%89%8B%E5%AE%9E%E6%93%8D/2025-10-02-%E3%80%90%E5%8A%A8%E6%89%8B%E5%AE%9E%E6%93%8D%E3%80%91%E5%9C%A8%E6%9C%AC%E5%9C%B0%E8%BF%9B%E8%A1%8C%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/">
                     
										    在本地进行NLP大模型的微调
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2025/12/27/03%20AI%E5%AD%A6%E4%B9%A0/09%20%E5%8A%A8%E6%89%8B%E5%AE%9E%E6%93%8D/2025-12-27-%E3%80%90%E5%8A%A8%E6%89%8B%E5%AE%9E%E6%93%8D%E3%80%91%E5%9C%A8%E6%9C%AC%E5%9C%B0%E8%AE%AD%E7%BB%83%E4%B8%AD%E5%9B%BD%E5%90%8D%E8%91%97NanoGPT/">
                     
										    动手实操 - 在本地训练中国名著NanoGPT
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2026/01/01/03%20AI%E5%AD%A6%E4%B9%A0/09%20%E5%8A%A8%E6%89%8B%E5%AE%9E%E6%93%8D/2026-01-01-%E3%80%90%E5%8A%A8%E6%89%8B%E5%AE%9E%E6%93%8D%E3%80%91%E5%9C%A8%E6%9C%AC%E5%9C%B0%E4%BD%BF%E7%94%A8Dify%E6%9E%84%E5%BB%BAAgent/">
                     
										    动手实操 - 在本地使用Dify构建Agent
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="file active">
									<a href="/2025/05/05/03%20AI%E5%AD%A6%E4%B9%A0/2025-01-01-%E3%80%90%E4%B8%B4%E6%97%B6%E8%AE%B0%E5%BD%95%E3%80%91%E4%BE%9B%E5%90%8E%E7%BB%AD%E7%BB%86%E5%8C%96/">
                     
										    临时课题记录
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2025/10/05/03%20AI%E5%AD%A6%E4%B9%A0/2025-10-01-%E3%80%90AI%E6%B4%9E%E5%AF%9F%E3%80%91%E4%B8%9A%E7%95%8C%E6%B4%9E%E5%AF%9F%E7%BD%91%E5%9D%80/">
                     
										    AI洞察 - 业界趋势洞察材料与网址
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										08 业界厂商
									</a>
									
							<ul>
								<li class="file">
									<a href="/2025/10/05/08%20%E4%B8%9A%E7%95%8C%E5%8E%82%E5%95%86/2025-10-06-%E3%80%90AI%E5%8E%82%E5%95%86%E3%80%91%E8%8B%B1%E4%BC%9F%E8%BE%BE/">
                     
										    英伟达
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2025/10/05/08%20%E4%B8%9A%E7%95%8C%E5%8E%82%E5%95%86/2025-10-10-%E3%80%90AI%E5%8E%82%E5%95%86%E3%80%91%E9%98%BF%E9%87%8C%E4%BA%91/">
                     
										    阿里云
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										DeepSeek
									</a>
									
							<ul>
								<li class="file">
									<a href="/2025/10/05/08%20%E4%B8%9A%E7%95%8C%E5%8E%82%E5%95%86/DeepSeek/2025-10-07-%E3%80%90AI%E6%A8%A1%E5%9E%8B%E3%80%91DeepSeek%20V3%E5%92%8CR1/">
                     
										    DeepSeek V3和R1技术创新
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2025/10/05/08%20%E4%B8%9A%E7%95%8C%E5%8E%82%E5%95%86/DeepSeek/2025-10-08-%E3%80%90AI%E6%A8%A1%E5%9E%8B%E3%80%91DeepSeek%20V3.2%E5%92%8CDSA/">
                     
										    DeepSeek V3.2及核心技术DSA细粒度稀疏注意力机制
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2025/11/02/08%20%E4%B8%9A%E7%95%8C%E5%8E%82%E5%95%86/DeepSeek/2025-10-09-%E3%80%90AI%E6%A8%A1%E5%9E%8B%E3%80%91DeepSeek%20OCR/">
                     
										    DeepSeek OCR模型技术与意义解析
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										09 日常记录
									</a>
									
							<ul>
								<li class="file">
									<a href="/2025/10/05/09%20%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/2025-10-15-%E3%80%90%E4%B8%AA%E4%BA%BA%E8%AE%B0%E5%BD%95%E3%80%91%E6%B5%B7%E5%A4%96%E5%9B%BD%E5%AE%B6%E8%B6%B3%E8%BF%B9/">
                     
										    这些年走过的国家和城市
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2025/11/05/09%20%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/2025-11-01-%E3%80%90%E4%B8%AA%E4%BA%BA%E8%AE%B0%E5%BD%95%E3%80%91%E5%9C%9F%E8%80%B3%E5%85%B6%E5%8D%A1%E5%B8%95%E5%A4%9A%E5%A5%87%E4%BA%9A/">
                     
										    个人记录 - 土耳其卡帕多奇亚
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2025/10/05/2025-01-01-%E3%80%90%E6%96%87%E6%A1%A3%E5%88%86%E7%B1%BB%E3%80%91%E6%96%87%E6%A1%A3%E5%90%8D%E7%A7%B0%20%E6%A8%A1%E6%9D%BF/">
                     
										    AI洞察 - 业界趋势洞察材料与网址
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
		</div>
	</div>
</div>

	<!-- 引入正文 -->
	<div id="content" class="content">
		<h1 id="article-title">
	临时课题记录
</h1>

<!-- meta -->
<div class="article-meta">
	

	<span>十二亚晖</span>
	<span>2025-05-05 09:00:00</span>

  <div id="article-categories">
    
		  <span>Categories：</span>
      
          
              <span>
                  <i class="fa fa-folder" aria-hidden="true">
                  <a href="/categories/AI/">AI</a>
                  </i>
                
              </span>
          
      
    

    
		    <span>Tags：</span>
        
            
                <span>
                    <i class="fa fa-tag" aria-hidden="true">
                    <a href="/tags/AI/">AI</a>
                    </i>
                </span>
            
        
            
                <span>
                    <i class="fa fa-tag" aria-hidden="true">
                    <a href="/tags/技术/">技术</a>
                    </i>
                </span>
            
        
            
                <span>
                    <i class="fa fa-tag" aria-hidden="true">
                    <a href="/tags/学习/">学习</a>
                    </i>
                </span>
            
        
    
  </div>

</div>

<!-- content -->
<div id="article-content">
	<p>待分析知识点：</p>
<hr>
<p>AI token的消耗很大一部分是使用模型做角色扮演，尤其在国外市场。这种角色扮演很多直接使用开源模型。角色扮演主要是一些什么样的业务，是2B还是2C，对模型、应用等有一些什么样的要求？</p>
<p>AI 角色扮演（AI Roleplay, 简称 RP）确实是目前大语言模型（LLM）Token 消耗的“大户”，尤其在海外市场，它已经演变成一个极其庞大且细分的产业。</p>
<p>这种业务主要分为 <strong>2C（面向消费者）</strong> 和 <strong>2B（面向企业）</strong> 两大阵营，两者在模型选择和应用逻辑上有着显著差异。</p>
<hr>
<h2 id="1-2C-业务：情感寄托与沉浸式娱乐"><a href="#1-2C-业务：情感寄托与沉浸式娱乐" class="headerlink" title="1. 2C 业务：情感寄托与沉浸式娱乐"></a>1. 2C 业务：情感寄托与沉浸式娱乐</h2><p>这是目前 Token 消耗最疯狂的领域，代表产品如 <strong>Character.ai</strong>、<strong>JanitorAI</strong>、<strong>Candy.ai</strong> 等。</p>
<ul>
<li><p><strong>核心场景：</strong></p>
</li>
<li><p><strong>虚拟伴侣&#x2F;恋爱：</strong> 用户与喜欢的动漫角色、影视明星或虚构的理想型建立情感联系。</p>
</li>
<li><p><strong>沉浸式游戏剧本（Text Adventure）：</strong> 模型充当“地下城主”（DM），引导用户进入奇幻、科幻或恐怖世界。</p>
</li>
<li><p><strong>“非和谐”内容（NSFW）：</strong> 海外市场中，不受限的情感和感官交流是开源模型 RP 爆发的直接诱因（因为闭源模型如 GPT-4 限制极多）。</p>
</li>
<li><p><strong>模型与应用要求：</strong></p>
</li>
<li><p><strong>超长上下文（Context Window）：</strong> 角色扮演通常涉及长达数周甚至数月的对话，模型必须“记得”半个月前聊过的细节，否则会“出戏”。</p>
</li>
<li><p><strong>人格一致性：</strong> 模型不能轻易受引导而崩人设。</p>
</li>
<li><p><strong>开源模型是主力：</strong> 开发者大量使用 <strong>Llama 3</strong>、<strong>Mistral</strong> 或 <strong>Gemma</strong> 的微调版（如 <em>Llama-3-8B-Instruct-Abliterated</em> 等），因为这些模型没有审核过滤器，且推理成本极低。</p>
</li>
</ul>
<hr>
<h2 id="2-2B-业务：职业实操与技能演练"><a href="#2-2B-业务：职业实操与技能演练" class="headerlink" title="2. 2B 业务：职业实操与技能演练"></a>2. 2B 业务：职业实操与技能演练</h2><p>2B 的角色扮演更偏向“仿真模拟”，旨在解决企业培训中“人对人演练”成本高、尴尬、不可量化的问题。</p>
<ul>
<li><p><strong>核心场景：</strong></p>
</li>
<li><p><strong>销售&#x2F;客服对练（Sales RP）：</strong> 模拟“刁难型客户”、“犹豫不决型客户”，让新员工练习处理异议和成单技巧。</p>
</li>
<li><p><strong>领导力与沟通培训：</strong> 模拟“如何解雇表现不佳的员工”或“处理跨部门冲突”。</p>
</li>
<li><p><strong>医疗&#x2F;法律咨询模拟：</strong> 医学生模拟接诊带有情绪的患者，练习人文关怀。</p>
</li>
<li><p><strong>模型与应用要求：</strong></p>
</li>
<li><p><strong>结构化打分与反馈：</strong> 2B 的 RP 往往不是聊完就结束了，系统需要根据预设的“KPI”（如：是否使用了专业术语、是否表现出共情）进行实时评分。</p>
</li>
<li><p><strong>语音实时性（Latency）：</strong> 2B 场景多为语音 RP，要求模型响应极快（通常使用 Groq 这种推理引擎或本地高性能集群）。</p>
</li>
<li><p><strong>知识库挂载（RAG）：</strong> AI 扮演的客户必须对企业的特定产品细节了如指掌。</p>
</li>
</ul>
<hr>
<h2 id="3-对模型和技术栈的具体要求"><a href="#3-对模型和技术栈的具体要求" class="headerlink" title="3. 对模型和技术栈的具体要求"></a>3. 对模型和技术栈的具体要求</h2><p>无论 2B 还是 2C，要做好 RP 业务，模型通常需要满足以下“硬杠杠”：</p>
<table>
<thead>
<tr>
<th>维度</th>
<th>要求说明</th>
</tr>
</thead>
<tbody><tr>
<td><strong>创造力（Creativity）</strong></td>
<td>拒绝“机器人式”回复，需要有语气词、情绪描写和生动的动作描述。</td>
</tr>
<tr>
<td><strong>抗遗忘能力</strong></td>
<td>在长对话中精准提取信息。目前多采用 <strong>Vector DB (向量数据库)</strong> + <strong>Long Context</strong> 方案。</td>
</tr>
<tr>
<td><strong>推理成本控制</strong></td>
<td>2C 用户的对话量惊人，必须通过 <strong>量化（Quantization）</strong> 技术在低显存下运行大模型。</td>
</tr>
<tr>
<td><strong>多模态支持</strong></td>
<td>现在的 RP 趋向于“语、音、图”一体化。用户发一张照片，AI 角色需要给出带情绪的点评。</td>
</tr>
</tbody></table>
<hr>
<p>那2C的角色扮演业务，是以纯文本语言的NLP模型为主，还是结合了多模态的能力，能够生成图像和视频呢？</p>
<p>在目前的 2C 角色扮演（RP）业务中，<strong>纯文本（NLP）是灵魂和骨架，但多模态（图像、语音、甚至视频）已经成为核心竞争力。</strong></p>
<p>简单的“文字聊天机器人”已经很难在海外激烈的 2C 市场生存。现在的趋势是**“以文本为核心，全方位多模态化”**。</p>
<hr>
<h3 id="1-文本模型：依然是“大脑”"><a href="#1-文本模型：依然是“大脑”" class="headerlink" title="1. 文本模型：依然是“大脑”"></a>1. 文本模型：依然是“大脑”</h3><p>尽管有了图像和视频，<strong>NLP 模型依然是所有体验的根基</strong>。</p>
<ul>
<li><strong>逻辑支撑：</strong> 图像和视频的生成高度依赖文本模型产生的“描述语”（Prompt）。比如 AI 角色在海边给你发一张合照，首先需要 NLP 模型意识到“我们现在在海边”，并生成相应的场景描述。</li>
<li><strong>情感连接：</strong> 用户的粘性来自于对话的深度、角色的性格一致性以及“懂我”的感觉，这些目前只能靠文本模型实现。</li>
</ul>
<h3 id="2-图像能力：从“静态头像”到“实时自拍”"><a href="#2-图像能力：从“静态头像”到“实时自拍”" class="headerlink" title="2. 图像能力：从“静态头像”到“实时自拍”"></a>2. 图像能力：从“静态头像”到“实时自拍”</h3><p>这是目前 2C RP 产品中最成熟、最普及的多模态功能。</p>
<ul>
<li><strong>实时自拍（Selfies）：</strong> 像 <strong>Kindroid</strong> 和 <strong>Nomi</strong> 这种头部产品，允许用户随时要求角色“发一张你现在的照片”。系统会结合当前的对话情境（比如正在咖啡馆、穿着红色裙子）即时生成一张视觉统一的照片。</li>
<li><strong>视觉理解（Vision）：</strong> 用户发一张自己的午餐照片，AI 角色能“看懂”并评价：“哇，这个拉面看起来很辣，记得多喝水。”这种双向的视觉互动极大增强了沉浸感。</li>
</ul>
<h3 id="3-语音与视频：正在爆发的新战场"><a href="#3-语音与视频：正在爆发的新战场" class="headerlink" title="3. 语音与视频：正在爆发的新战场"></a>3. 语音与视频：正在爆发的新战场</h3><ul>
<li><strong>实时语音通话：</strong> 许多应用（如 <strong>Replika</strong>、<strong>Character.ai</strong>）已经支持流畅的语音通话。这不仅是 TTS（文字转语音），还包括情感渲染，即 AI 会根据对话内容表现出害羞、生气或兴奋的语气。</li>
<li><strong>2.5D&#x2F;3D 虚拟形象：</strong> 像 <strong>Replika</strong> 提供可交互的 3D 建模，用户可以给角色换装、布置房间。</li>
<li><strong>短视频&#x2F;动画生成：</strong> 这是目前的尖端趋势。一些产品开始尝试让 AI 角色发送几秒钟的短视频或动态表情包（类似 Live2D 或基于视频生成的动态反馈），虽然成本较高，但在高端付费用户中极受欢迎。</li>
</ul>
<hr>
<h3 id="4-技术实现：由“拼图式”向“原生式”演进"><a href="#4-技术实现：由“拼图式”向“原生式”演进" class="headerlink" title="4. 技术实现：由“拼图式”向“原生式”演进"></a>4. 技术实现：由“拼图式”向“原生式”演进</h3><p>目前市面上的实现方案主要分为两种：</p>
<table>
<thead>
<tr>
<th>方案类型</th>
<th>实现方式</th>
<th>特点</th>
</tr>
</thead>
<tbody><tr>
<td><strong>拼图式 (Modular)</strong></td>
<td><strong>LLM</strong> (大脑) + <strong>Stable Diffusion</strong> (图像) + <strong>So-VITS</strong> (语音)</td>
<td><strong>主流方案</strong>。灵活性高，开发者可以用开源模型自由组合，成本相对可控，但在跨模态的一致性上需要大量调优。</td>
</tr>
<tr>
<td><strong>原生多模态 (Native)</strong></td>
<td>使用类似 <strong>GPT-4o</strong> 或 <strong>Gemini 1.5</strong> 这种原生支持多模态输入的模型</td>
<td><strong>未来趋势</strong>。AI 能直接“感受”图像和声音，不需要经过文字中转，反应更自然，但目前高性能的原生模型多为闭源，限制多且贵。</td>
</tr>
</tbody></table>
<hr>
<h3 id="5-总结：多模态对业务的价值"><a href="#5-总结：多模态对业务的价值" class="headerlink" title="5. 总结：多模态对业务的价值"></a>5. 总结：多模态对业务的价值</h3><p>对于 2C 厂商来说，加入多模态能力不只是为了“好看”，而是有直接的商业逻辑：</p>
<ol>
<li><strong>提高付费转化率：</strong> 用户可能愿意为“解锁角色的私密照”或“语音通话功能”支付订阅费。</li>
<li><strong>增加 Token 消耗与留存：</strong> 图像和语音的互动会诱发用户产生更多对话，形成正向循环。</li>
<li><strong>降低门槛：</strong> 视觉直观的反馈比纯文字更能吸引泛娱乐用户（非硬核文学爱好者）。</li>
</ol>
<p><strong>如果您关注的是开发层面，目前最火的玩法是：用微调过的 Llama 3 做逻辑层，挂载一个特定的 Stable Diffusion LoRA 模型来保证角色长相永远不变。您想深入了解这种“角色一致性”的技术实现吗？</strong></p>
<hr>
<h2 id="4-为什么大家都在用开源模型？"><a href="#4-为什么大家都在用开源模型？" class="headerlink" title="4. 为什么大家都在用开源模型？"></a>4. 为什么大家都在用开源模型？</h2><p>除了成本考虑外，**“定制化微调”**是关键。<br>开源社区（如 Hugging Face）有成千上万个专门针对“Storytelling”或“Roleplay”微调过的模型（例如 <em>Mistral-Nemo-12B-Minitron</em> ），它们在写小说、描写心理活动方面，甚至比某些通用闭源大模型更有“人味儿”。</p>
<h2 id="您是否是对某个特定的角色扮演应用赛道感兴趣，或者是想了解如何针对-RP-场景对模型进行微调？"><a href="#您是否是对某个特定的角色扮演应用赛道感兴趣，或者是想了解如何针对-RP-场景对模型进行微调？" class="headerlink" title="您是否是对某个特定的角色扮演应用赛道感兴趣，或者是想了解如何针对 RP 场景对模型进行微调？"></a><strong>您是否是对某个特定的角色扮演应用赛道感兴趣，或者是想了解如何针对 RP 场景对模型进行微调？</strong></h2><hr>
<h1 id="未完成-动手实操："><a href="#未完成-动手实操：" class="headerlink" title="未完成 - 动手实操："></a>未完成 - 动手实操：</h1><p>1.手搓一个NLP大模型。参考B站的简单版指导，给出详细过程。</p>
<p>2.基于Dify搭建企业知识库，读取本地文章。</p>
<p>3.华为云Versatile的体验使用</p>
<h1 id="未完成-知识学习："><a href="#未完成-知识学习：" class="headerlink" title="未完成 - 知识学习："></a>未完成 - 知识学习：</h1><ol>
<li><p>大模型训练框架和推理框架各自是做什么的。 各个厂家的训练框架和推理框架各是哪些。</p>
</li>
<li><p>AI训练加速引擎到底做什么，包括一些高性能通信库、算子定义等等。这些跟基础的训练框架，以及跨多节点的训练调度是什么关系？</p>
</li>
</ol>
<hr>
<p>简单来说，<strong>训练框架</strong>是整场战役的“指挥官”和“架构师”，而<strong>训练加速引擎</strong>则是士兵手中的“神兵利器”或“兴奋剂”。</p>
<p>我们可以从以下几个维度来理解它们的关系和分工：</p>
<h3 id="1-训练框架-Training-Framework-——-“运筹帷幄的指挥官”"><a href="#1-训练框架-Training-Framework-——-“运筹帷幄的指挥官”" class="headerlink" title="1. 训练框架 (Training Framework) —— “运筹帷幄的指挥官”"></a>1. 训练框架 (Training Framework) —— “运筹帷幄的指挥官”</h3><p>代表产品：英伟达 <strong>Megatron-LM</strong>、微软 <strong>DeepSpeed</strong>、华为 <strong>MindSpore</strong>、阿里 <strong>PAI-TorchAcc</strong> 等。</p>
<p>在大模型（LLM）时代，模型由于太大，单张显卡根本放不下。训练框架的核心任务是解决**“如何把庞然大物拆分到成千上万张显卡上同步训练”**的问题。</p>
<ul>
<li><strong>核心功能：</strong></li>
<li><strong>并行策略（并行大法）：</strong> 决定模型怎么拆。包括<strong>张量并行</strong>（把一层拆开）、<strong>流水线并行</strong>（把不同层分给不同卡）、<strong>数据并行</strong>（每张卡练不同数据）。</li>
<li><strong>显存管理：</strong> 通过“重计算（Checkpointing）”或“显存卸载（Offload）”技术，让有限的显卡内存能跑更大的模型。</li>
<li><strong>分布式调度：</strong> 像交警一样指挥几千张显卡之间的数据交换（通信），确保大家不打架、不阻塞。</li>
<li><strong>断点续训：</strong> 训练几周甚至几个月，万一哪张卡坏了，框架要能自动从最近的备份点恢复。</li>
</ul>
<hr>
<h3 id="2-训练加速引擎-Acceleration-Engine-——-“局部战场的特种兵”"><a href="#2-训练加速引擎-Acceleration-Engine-——-“局部战场的特种兵”" class="headerlink" title="2. 训练加速引擎 (Acceleration Engine) —— “局部战场的特种兵”"></a>2. 训练加速引擎 (Acceleration Engine) —— “局部战场的特种兵”</h3><p>代表产品：英伟达 <strong>Transformer Engine (TE)</strong>、阿里云 <strong>Deepytorch Training</strong>、字节跳动 <strong>LightSeq</strong> 等。</p>
<p>加速引擎通常不是一个独立的指挥系统，而是<strong>嵌入在框架里</strong>或者<strong>作为插件</strong>使用的。它的目标非常纯粹：<strong>让每一张显卡算得更快，让卡与卡之间传得更稳。</strong></p>
<ul>
<li><strong>核心功能：</strong></li>
<li><strong>算子融合 (Operator Fusion)：</strong> 把几十个小的数学运算（比如加法、乘法、激活）打包成一个大的计算任务，减少 GPU 反复读写内存的次数。</li>
<li><strong>低精度计算 (FP8&#x2F;BF16)：</strong> 让显卡用更简单的数字格式去算，计算量减半，速度翻倍。比如英伟达 H100 的 <strong>Transformer Engine</strong> 专门针对 FP8 格式做了硬件级的加速。</li>
<li><strong>通信优化：</strong> 优化显卡之间交换数据的算法（如 NCCL 库的深度定制），减少 CPU 和 GPU 之间的无效等待。</li>
<li><strong>计算图编译：</strong> 在正式开跑前，把代码翻译成机器最容易理解的“捷径”，去掉冗余步骤。</li>
</ul>
<hr>
<h3 id="3-两者之间的关系：相辅相成"><a href="#3-两者之间的关系：相辅相成" class="headerlink" title="3. 两者之间的关系：相辅相成"></a>3. 两者之间的关系：相辅相成</h3><p>如果把大模型训练比作<strong>盖摩天大楼</strong>：</p>
<ul>
<li><strong>训练框架</strong>是<strong>施工方案和塔吊系统</strong>。它决定了楼怎么分段盖（并行）、材料怎么运（通信）、坏了怎么补（容错）。</li>
<li><strong>训练加速引擎</strong>是<strong>高强度混凝土和电动工具</strong>。它让每一块砖（算子）凝固得更快，让工人干活的手速变快。</li>
</ul>
<p><strong>为什么云厂家都要搞自己的加速引擎？</strong><br>因为云厂家（如阿里、腾讯、华为）底层硬件环境不同。他们会在开源框架（如 PyTorch）的基础上，针对自家的网络带宽、自研芯片或存储特性，开发一套专门的加速引擎。</p>
<ul>
<li><strong>通用框架</strong>保证了“能跑通”和“好上手”。</li>
<li><strong>厂家加速引擎</strong>保证了“跑得最省钱、最快”。</li>
</ul>
<hr>
<h3 id="总结对比"><a href="#总结对比" class="headerlink" title="总结对比"></a>总结对比</h3><table>
<thead>
<tr>
<th>维度</th>
<th>训练框架 (如 Megatron-LM)</th>
<th>训练加速引擎 (如 TorchAcc&#x2F;TE)</th>
</tr>
</thead>
<tbody><tr>
<td><strong>关注点</strong></td>
<td>宏观：分布式架构、并行模式</td>
<td>微观：单卡算力利用率、通信效率</td>
</tr>
<tr>
<td><strong>解决痛点</strong></td>
<td>模型太大装不下、卡太多不好管</td>
<td>计算太慢、显存浪费、通信堵塞</td>
</tr>
<tr>
<td><strong>存在形式</strong></td>
<td>完整的代码仓库&#x2F;库</td>
<td>算子库、编译器插件、底层指令集</td>
</tr>
<tr>
<td><strong>直观感受</strong></td>
<td>“我可以跑万亿参数模型了”</td>
<td>“同样的卡，我的训练时间缩短了 30%”</td>
</tr>
</tbody></table>
<p><strong>你想深入了解某个具体的加速技术（比如 FP8 精度训练或是张量并行），还是想知道如何根据自己的算力规模选择合适的框架？</strong></p>
<hr>
<p>业界主流训练框架对比：</p>
<p>没问题，我将之前的核心维度与新增的<strong>并行策略复杂度</strong>、<strong>硬件亲密度</strong>以及<strong>资源需求</strong>整合在一起。这张表可以作为你进行大模型训练技术选型时的全景参考。</p>
<h3 id="业界主流大模型训练框架全维度对比表"><a href="#业界主流大模型训练框架全维度对比表" class="headerlink" title="业界主流大模型训练框架全维度对比表"></a>业界主流大模型训练框架全维度对比表</h3><table>
<thead>
<tr>
<th>厂商类别</th>
<th>厂商名称</th>
<th>框架名称</th>
<th>并行策略复杂度 (操控性)</th>
<th>硬件亲密度 (底层耦合)</th>
<th>核心优势</th>
<th>劣势与挑战</th>
<th>适合场景</th>
</tr>
</thead>
<tbody><tr>
<td><strong>硬件巨头</strong></td>
<td><strong>NVIDIA</strong></td>
<td><strong>Megatron-LM</strong></td>
<td><strong>极高 (手动挡)</strong>：需精细调整 TP&#x2F;PP 参数</td>
<td><strong>原生级</strong>：专为英伟达 GPU 架构及 NVLink 优化</td>
<td>极限性能最强，是大规模集群的性能基准</td>
<td>学习曲线极陡峭，对非 NVIDIA 硬件零支持</td>
<td><strong>万亿级参数</strong>、超大规模 GPU 集群的预训练</td>
</tr>
<tr>
<td><strong>基础软件</strong></td>
<td><strong>Microsoft</strong></td>
<td><strong>DeepSpeed</strong></td>
<td><strong>中低 (自动挡)</strong>：ZeRO 技术实现自动化显存优化</td>
<td><strong>中间件</strong>：适配所有支持 PyTorch 的硬件</td>
<td><strong>易用性无敌</strong>，普通显卡也能练大模型</td>
<td>极致通信效率略逊于 Megatron 的精调</td>
<td><strong>SFT(微调)</strong>、中型企业研发、快速验证</td>
</tr>
<tr>
<td><strong>国内领军</strong></td>
<td><strong>华为</strong></td>
<td><strong>MindSpore</strong></td>
<td><strong>中 (智能档)</strong>：支持自动并行策略搜索</td>
<td><strong>原生级</strong>：针对昇腾 NPU 指令集深度调优</td>
<td><strong>全栈国产化安全</strong>，算子下沉性能优异</td>
<td>生态相对独立，迁移开源模型需适配成本</td>
<td><strong>政府&#x2F;金融&#x2F;央企</strong>等对国产化有硬性要求的项目</td>
</tr>
<tr>
<td><strong>云厂商</strong></td>
<td><strong>阿里巴巴</strong></td>
<td><strong>PAI-TorchAcc</strong></td>
<td><strong>低 (管家式)</strong>：编译器自动发现并行机会</td>
<td><strong>强耦合</strong>：深度绑定阿里云神龙架构与网络</td>
<td><strong>免改代码</strong>，云端网络通信效率极高</td>
<td>必须在阿里云环境下使用，跨云迁移难</td>
<td><strong>阿里云用户</strong>，追求极高显卡利用率(MFU)的企业</td>
</tr>
<tr>
<td><strong>云厂商</strong></td>
<td><strong>AWS</strong></td>
<td><strong>SageMaker</strong></td>
<td><strong>低 (管家式)</strong>：侧重流水线与数据管理自动化</td>
<td><strong>适配层</strong>：针对 AWS 自研芯片及 A100 优化</td>
<td>强大的<strong>工程稳定性和合规性</strong>，适合全球部署</td>
<td>商业闭源，按使用量收费，成本控制需精细</td>
<td><strong>跨国大型企业</strong>，对训练全流程合规有要求的场景</td>
</tr>
<tr>
<td><strong>国产开源</strong></td>
<td><strong>百度</strong></td>
<td><strong>PaddlePaddle</strong></td>
<td><strong>中 (全功能)</strong>：支持 4D 混合并行并行方案</td>
<td><strong>原生级</strong>：适配国产及国外主流芯片</td>
<td><strong>中文文档完备</strong>，工业级预训练模型库丰富</td>
<td>国际生态兼容性略逊于 PyTorch 体系</td>
<td><strong>国内工业&#x2F;教育领域</strong>，以及希望快速复用文心底座的厂家</td>
</tr>
</tbody></table>
<hr>
<h3 id="如何解读这两个关键维度？"><a href="#如何解读这两个关键维度？" class="headerlink" title="如何解读这两个关键维度？"></a>如何解读这两个关键维度？</h3><ol>
<li><strong>并行策略复杂度（手动挡 vs 自动挡）：</strong></li>
</ol>
<ul>
<li><strong>手动挡 (Megatron)：</strong> 你需要手动指定模型怎么切分。如果参数设错，程序会直接 OOM（显存溢出）或者运行极慢。但一旦调优，它能跑出硬件的极限。</li>
<li><strong>自动挡 (DeepSpeed&#x2F;vLLM)：</strong> 框架帮你处理了复杂的显存交换逻辑，你只需要关注模型层数和数据。</li>
</ul>
<ol start="2">
<li><strong>硬件亲密度（原生 vs 中间件）：</strong></li>
</ol>
<ul>
<li><strong>原生级 (Megatron&#x2F;MindSpore)：</strong> 直接调用硬件最底层的“暗黑技巧”（如特定指令集），就像为特定脚型定制的赛跑鞋。</li>
<li><strong>中间件 (DeepSpeed)：</strong> 像是一双高性能运动鞋，穿在谁脚上都能跑得快，但对特定冠军选手的极限发挥可能少了一点极致加持。</li>
</ul>
<hr>
<h3 id="选型建议："><a href="#选型建议：" class="headerlink" title="选型建议："></a>选型建议：</h3><ul>
<li>如果你有 <strong>1024张以上的 H100</strong> 且追求极致效率：选 <strong>Megatron-LM</strong>。</li>
<li>如果你只有 <strong>几张或几十张显卡</strong> 想快速跑通微调：选 <strong>DeepSpeed</strong>。</li>
<li>如果你的算力资源都在 <strong>阿里云</strong> 上：直接用 <strong>PAI-TorchAcc</strong>。</li>
<li>如果项目涉及 <strong>国家信创&#x2F;安全</strong> 要求：首选 <strong>MindSpore + 昇腾</strong>。</li>
</ul>
<p><strong>这些框架里，你目前接触较多或者最感兴趣的是哪一个？我可以针对性地为你提供该框架的起步教程或核心参数避坑指南。</strong></p>
<h2 id="AI推理加速引擎又是做什么的，跟推理框架又有什么关系和区别？"><a href="#AI推理加速引擎又是做什么的，跟推理框架又有什么关系和区别？" class="headerlink" title="AI推理加速引擎又是做什么的，跟推理框架又有什么关系和区别？"></a>AI推理加速引擎又是做什么的，跟推理框架又有什么关系和区别？</h2><p>推理领域的关系确实与训练非常相似，但也存在一个核心的<strong>逻辑转变</strong>：训练关注的是“吞吐量”（单位时间内喂多少数据），而推理关注的是**“延迟”<strong>（用户发问后多久能回话）和</strong>“并发”**（多少人能同时在线问）。</p>
<p>在推理场景下，<strong>推理框架</strong>是“服务大厅的经理”，而<strong>推理加速引擎</strong>是“柜台前处理业务的神速员”。</p>
<hr>
<h3 id="1-推理框架-Serving-Framework-——-“服务大厅的经理”"><a href="#1-推理框架-Serving-Framework-——-“服务大厅的经理”" class="headerlink" title="1. 推理框架 (Serving Framework) —— “服务大厅的经理”"></a>1. 推理框架 (Serving Framework) —— “服务大厅的经理”</h3><p>代表产品：<strong>vLLM</strong>、<strong>TGI (Text Generation Inference)</strong>、<strong>NVIDIA Triton</strong>、<strong>Bentoml</strong>。</p>
<p>推理框架的任务是把一个静止的模型文件，变成一个可以 24 小时随时待命、支持成千上万用户调用的<strong>网络服务</strong>。</p>
<ul>
<li><strong>核心功能：</strong></li>
<li><strong>请求调度（动态批处理&#x2F;Continuous Batching）：</strong> 既然用户是随时进来的，框架需要把不同人的请求“拼”成一袋，喂给显卡，避免显卡空转。</li>
<li><strong>KV Cache 管理（如 PagedAttention）：</strong> 大模型生成文字时会产生大量缓存。框架要像管理内存条一样高效管理这些缓存，防止显存爆炸。</li>
<li><strong>多用户并发控制：</strong> 决定谁的请求先排队，谁的请求优先级高。</li>
<li><strong>API 封装：</strong> 提供标准的 OpenAI 接口或其他接口，让前端应用（如 App 或网页）能轻松接入。</li>
</ul>
<hr>
<h3 id="2-推理加速引擎-Inference-Engine-——-“神速的处理专员”"><a href="#2-推理加速引擎-Inference-Engine-——-“神速的处理专员”" class="headerlink" title="2. 推理加速引擎 (Inference Engine) —— “神速的处理专员”"></a>2. 推理加速引擎 (Inference Engine) —— “神速的处理专员”</h3><p>代表产品：<strong>TensorRT-LLM</strong>、<strong>FasterTransformer</strong>、<strong>OpenVINO</strong> (Intel)、<strong>Apple CoreML</strong>。</p>
<p>加速引擎不直接和用户打交道，它潜伏在框架内部，专门负责**“如何榨干硬件性能”**。它通常在模型上线前，先对模型进行一次“大手术”（编译优化）。</p>
<ul>
<li><strong>核心功能：</strong></li>
<li><strong>量化（Quantization）：</strong> 把模型的权重的“精度”从 16 位降到 4 位（INT4&#x2F;INT8），文件缩小 4 倍，速度提升数倍，而智商下降极小。</li>
<li><strong>图优化与算子融合：</strong> 把模型里几百道数学题合并成一道题。比如把“乘法+加法+激活”合并成一个动作，减少 GPU 读写次数。</li>
<li><strong>硬件深度适配：</strong> 比如针对英伟达 H100 的特定指令集做优化，这在通用框架里是很难做到的。</li>
<li><strong>内核替换（Kernel Replacement）：</strong> 把原本低效的通用代码替换成手写的高性能汇编代码（如 FlashAttention）。</li>
</ul>
<hr>
<h3 id="3-两者之间的关系：集成与互补"><a href="#3-两者之间的关系：集成与互补" class="headerlink" title="3. 两者之间的关系：集成与互补"></a>3. 两者之间的关系：集成与互补</h3><p>在实际部署中，通常是**“推理框架调用加速引擎”**。</p>
<ul>
<li><strong>vLLM</strong> 本身既是一个框架，也包含了自己的加速逻辑（PagedAttention）。</li>
<li><strong>TensorRT-LLM</strong> 是极致的加速引擎，但它不直接提供 Web 接口，通常需要配合 <strong>NVIDIA Triton</strong> 框架或者 <strong>vLLM</strong> 来对外服务。</li>
</ul>
<hr>
<h3 id="总结对比-1"><a href="#总结对比-1" class="headerlink" title="总结对比"></a>总结对比</h3><table>
<thead>
<tr>
<th>维度</th>
<th>推理框架 (如 vLLM, Triton)</th>
<th>推理加速引擎 (如 TensorRT-LLM)</th>
</tr>
</thead>
<tbody><tr>
<td><strong>第一目标</strong></td>
<td><strong>高并发</strong>、高可用、易部署</td>
<td><strong>低延迟</strong>、高吞吐、极致利用硬件</td>
</tr>
<tr>
<td><strong>主要任务</strong></td>
<td>排队调度、显存回收、接口响应</td>
<td>模型量化、算子融合、指令集优化</td>
</tr>
<tr>
<td><strong>操作对象</strong></td>
<td>用户的请求流（Requests）</td>
<td>模型的计算图（Computational Graph）</td>
</tr>
<tr>
<td><strong>打个比方</strong></td>
<td>餐厅的<strong>叫号系统和领班</strong></td>
<td>厨房里的<strong>全自动切菜机和快炒炉</strong></td>
</tr>
<tr>
<td><strong>决定了…</strong></td>
<td>你的系统能同时支持 10 个人还是 1000 个人</td>
<td>用户点下“发送”后 0.5 秒还是 5 秒出结果</td>
</tr>
</tbody></table>
<hr>
<h2 id="你是正在考虑为自己的模型搭建一套部署环境吗？我可以帮你对比一下目前最火的-vLLM-和英伟达原厂的-TensorRT-LLM-在具体性能和易用性上的差异。"><a href="#你是正在考虑为自己的模型搭建一套部署环境吗？我可以帮你对比一下目前最火的-vLLM-和英伟达原厂的-TensorRT-LLM-在具体性能和易用性上的差异。" class="headerlink" title="你是正在考虑为自己的模型搭建一套部署环境吗？我可以帮你对比一下目前最火的 vLLM 和英伟达原厂的 TensorRT-LLM 在具体性能和易用性上的差异。"></a><strong>你是正在考虑为自己的模型搭建一套部署环境吗？我可以帮你对比一下目前最火的 vLLM 和英伟达原厂的 TensorRT-LLM 在具体性能和易用性上的差异。</strong></h2><p>2.模型微调有哪些数据集，包括Hugging face上的开源数据集分一些什么样的类型？</p>
<ol start="3">
<li><p>企业数据集加工有哪些工具，如何处理。</p>
</li>
<li><p>提示词压缩</p>
</li>
</ol>
<p>5.从提示词工程到上下文工程。</p>
<ol start="6">
<li>LoRA微调详细学习。（缺数学原理部分内容笔记）</li>
</ol>
<hr>
<h1 id="已完成"><a href="#已完成" class="headerlink" title="已完成"></a>已完成</h1><p>（关闭）大模型的架构、参数等，在实体文件上是如何表示和对应的？</p>
<p>（关闭）动手实操：整理转换数据集，在线微调大模型</p>
<hr>
<p>GPU芯片</p>
<h1 id="CUDA核和Tensor核的区别"><a href="#CUDA核和Tensor核的区别" class="headerlink" title="CUDA核和Tensor核的区别"></a>CUDA核和Tensor核的区别</h1><p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/451127498">文章介绍</a></p>
<p>第2个评论回答的比较清楚。</p>
<p>tensor core 第一代是在volta架构上推出，专为深度学习而设计的，在tensor矩阵场景下算得更快。一个时钟周期内可以完成一个64 floating point 的FMA，而cuda core是搞不定的，分多次。</p>
<p><img src="https://vdn3.vzuu.com/SD/1fd55a3c-9362-11eb-a595-1278b449b310.mp4?auth_key=1761741592-0-0-19b21368bf65ad9cc817ada64d87bb08&bu=078babd7&c=avc.0.0&disable_local_cache=1&expiration=1761741592&f=mp4&pu=078babd7&v=tx" alt="形象对比"></p>
<h1 id="达芬奇架构NPU又有什么区别？"><a href="#达芬奇架构NPU又有什么区别？" class="headerlink" title="达芬奇架构NPU又有什么区别？"></a>达芬奇架构NPU又有什么区别？</h1><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/352481421">参考这里</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/389768549">参考这里</a></p>
<p>达芬奇架构，是华为自研的面向AI计算特征的全新计算架构，具备高算力、高能效、灵活可裁剪的特性，是实现万物智能的重要基础。具体来说，达芬奇架构采用3D Cube针对矩阵运算做加速，大幅提升单位功耗下的AI算力，每个AI Core可以在一个时钟周期内实现4096个MAC操作，相比传统的CPU和GPU实现数量级的提升。</p>
<p><img src="https://pic1.zhimg.com/v2-1f6368d7b412c07f92caa26eba6c1f1a_1440w.jpg" alt="架构图示"></p>
<h1 id="英伟达GPU和华为NPU的区别"><a href="#英伟达GPU和华为NPU的区别" class="headerlink" title="英伟达GPU和华为NPU的区别"></a>英伟达GPU和华为NPU的区别</h1><hr>
<p>（本文完））</p>

</div>

<!-- post-guide -->

    <div class="post-guide">
        <div class="item left">
            
              <a href="/2025/10/02/03%20AI%E5%AD%A6%E4%B9%A0/04%20AI%E6%A8%A1%E5%9E%8B%E4%B8%8E%E5%BA%94%E7%94%A8/2025-04-01-%E3%80%90%E6%A8%A1%E5%9E%8B%E5%90%8E%E8%AE%AD%E7%BB%83%E3%80%91%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%90%8E%E8%AE%AD%E7%BB%83%E4%B8%8E%E5%BE%AE%E8%B0%83/">
                  <i class="fa fa-angle-left" aria-hidden="true"></i>
                  后训练 - 大模型后训练与微调
              </a>
            
        </div>
        <div class="item right">
            
              <a href="/2025/05/05/03%20AI%E5%AD%A6%E4%B9%A0/00%20AI%E7%9F%A5%E8%AF%86%E5%9C%B0%E5%9B%BE/2025-10-05-%E3%80%90AI%E5%AD%A6%E4%B9%A0%E3%80%91AI%E7%9F%A5%E8%AF%86%E5%9C%B0%E5%9B%BE/">
                AI知识地图
                <i class="fa fa-angle-right" aria-hidden="true"></i>
              </a>
            
        </div>
    </div>


<!-- comment - giscus -->


<!-- comment - valine -->


<script>
	
	
</script>

	</div>
	<div id="footer">
	<p>
	©<span id="footerYear-start"></span>-<span id="footerYear-end"></span>

	
	    <a href="/">十二亚晖</a>
	
	
	
	<br>
	Theme <a href="//github.com/wujun234/hexo-theme-tree" target="_blank">Tree</a>
	by <a href="//wujun.me" target="_blank">Wu Jun</a>
	Powered by <a href="//hexo.io" target="_blank">Hexo</a>
	</p>
</div>


<script type="text/javascript">
	document.getElementById('footerYear-start').innerHTML = new Date().getFullYear() + '';
</script>

<script type="text/javascript">
	document.getElementById('footerYear-end').innerHTML = new Date().getFullYear() + '';
</script>

	<button id="totop-toggle" class="toggle"><i class="fa fa-angle-double-up" aria-hidden="true"></i></button>
</body>
</html>